import boto3
import json
import newrelic.agent
import openai
import os


# For this example to work, you should set the following environment variables
# to values that work for your specific environment.
#
#   NEW_RELIC_APP_NAME
#   NEW_RELIC_LICENSE_KEY
#   AWS_ACCESS_KEY_ID
#   AWS_SECRET_ACCESS_KEY
#   OPENAI_API_KEY
#


@newrelic.agent.background_task()
@newrelic.agent.function_trace(name="openai")
def runOpenAI(prompt, user_request):
    # change to 'gpt-4' if you have access to it
    model = "gpt-3.5-turbo"

    print(f"Running OpenAI with model {model}")

    openai.api_key = os.getenv("OPENAI_API_KEY")
    response = openai.ChatCompletion.create(
        model=model,
        max_tokens=500,
        messages=[
            {
                "role": "system",
                "content": prompt,
            },
            {
                "role": "user",
                "content": user_request,
            },
        ],
    )

    print("Response from ChatGPT\n")
    print(response["choices"][0]["message"]["content"])
    print("\n\n")


@newrelic.agent.background_task()
@newrelic.agent.function_trace(name="bedrock")
def runBedrock(prompt, user_request):
    """
    Run a query with AWS Bedrock using Anthropic Claude v2.
    """
    bedrock_runtime = boto3.client("bedrock-runtime", "us-east-1")
    full_prompt = f"{prompt}\n{user_request}"
    prompt_data = f"Human: ${full_prompt}\n\nAssistant:"
    body = json.dumps({"prompt": prompt_data, "max_tokens_to_sample": 500})
    modelId = "anthropic.claude-v2"
    accept = "application/json"
    contentType = "application/json"

    print(f"Running Bedrock with model {modelId}")

    response = bedrock_runtime.invoke_model(
        body=body, modelId=modelId, accept=accept, contentType=contentType
    )
    response_body = json.loads(response.get("body").read())

    print("Response from Bedrock")
    print(response_body.get("completion"))
    print("\n\n")


if __name__ == "__main__":
    # Enable New Relic Python agent. You must make sure your application name is either defined in the ini file below
    # or in the environment variable NEW_RELIC_APP_NAME
    newrelic.agent.initialize("newrelic.ini")
    newrelic.agent.register_application(timeout=10)

    # Enable New Relic observability for LLMs
    from nr_openai_observability import monitor

    monitor.initialization()

    # prompt is credited to https://prompts.chat/#act-as-a-math-teacher
    prompt = """I want you to act as a math teacher. 
    I will provide some mathematical equations or concepts, 
    and it will be your job to explain them in easy-to-understand terms. 
    This could include providing step-by-step instructions for solving a problem, 
    demonstrating various techniques with visuals or suggesting online 
    resources for further study."""
    user_request = (
        'My first request is â€œI need help understanding how probability works."'
    )

    runOpenAI(prompt, user_request)
    runBedrock(prompt, user_request)

    # Allow the New Relic agent to send final messages as part of shutdown
    # The agent by default can send data up to a minute later
    newrelic.agent.shutdown_agent(60)
